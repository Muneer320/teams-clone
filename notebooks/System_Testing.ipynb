{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f36129",
   "metadata": {},
   "source": [
    "# System Testing & Debugging\n",
    "\n",
    "Comprehensive testing suite for the Teams Clone application.\n",
    "\n",
    "## Features:\n",
    "- üîç Health checks and connectivity tests\n",
    "- üéØ Integration testing\n",
    "- ‚ö° Performance benchmarking\n",
    "- üêõ Error detection and diagnostics\n",
    "- üìä Test result reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04680ae7",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5656860f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\users\\munee\\appdata\\roaming\\python\\python313\\site-packages (2.32.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\munee\\appdata\\roaming\\python\\python313\\site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\munee\\appdata\\roaming\\python\\python313\\site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in c:\\users\\munee\\appdata\\roaming\\python\\python313\\site-packages (0.13.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement time (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for time\n"
     ]
    }
   ],
   "source": [
    "!pip install requests pandas matplotlib seaborn time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b83c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete!\n",
      "Testing against: http://localhost:3001\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration\n",
    "BASE_URL = \"http://localhost:3001\"\n",
    "test_results = []\n",
    "\n",
    "# Test user credentials\n",
    "TEST_USER = {\n",
    "    \"username\": f\"test_user_{int(time.time())}\",\n",
    "    \"password\": \"testpass123\",\n",
    "    \"name\": \"Test User\"\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "print(f\"Testing against: {BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161c3650",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae50113",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestResult:\n",
    "    def __init__(self, name, category):\n",
    "        self.name = name\n",
    "        self.category = category\n",
    "        self.start_time = time.time()\n",
    "        self.end_time = None\n",
    "        self.duration = None\n",
    "        self.passed = False\n",
    "        self.error = None\n",
    "    \n",
    "    def finish(self, passed, error=None):\n",
    "        self.end_time = time.time()\n",
    "        self.duration = self.end_time - self.start_time\n",
    "        self.passed = passed\n",
    "        self.error = error\n",
    "        return self\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'category': self.category,\n",
    "            'passed': self.passed,\n",
    "            'duration': round(self.duration * 1000, 2) if self.duration else 0,  # ms\n",
    "            'error': str(self.error) if self.error else None\n",
    "        }\n",
    "\n",
    "def run_test(name, category, test_func):\n",
    "    \"\"\"Run a test and record results\"\"\"\n",
    "    result = TestResult(name, category)\n",
    "    try:\n",
    "        test_func()\n",
    "        result.finish(True)\n",
    "        print(f\"‚úÖ {name} - PASSED ({result.duration*1000:.2f}ms)\")\n",
    "    except Exception as e:\n",
    "        result.finish(False, e)\n",
    "        print(f\"‚ùå {name} - FAILED: {e}\")\n",
    "    \n",
    "    test_results.append(result.to_dict())\n",
    "    return result\n",
    "\n",
    "def assert_status(response, expected_status):\n",
    "    \"\"\"Assert response status code\"\"\"\n",
    "    if response.status_code != expected_status:\n",
    "        raise AssertionError(f\"Expected {expected_status}, got {response.status_code}: {response.text}\")\n",
    "\n",
    "def assert_json_keys(data, *keys):\n",
    "    \"\"\"Assert JSON response contains keys\"\"\"\n",
    "    for key in keys:\n",
    "        if key not in data:\n",
    "            raise AssertionError(f\"Missing key: {key}\")\n",
    "\n",
    "print(\"‚úÖ Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c1789a",
   "metadata": {},
   "source": [
    "## 3. Health & Connectivity Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5559fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîç HEALTH & CONNECTIVITY TESTS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "def test_server_reachable():\n",
    "    response = requests.get(BASE_URL, timeout=5)\n",
    "    assert_status(response, 200)\n",
    "\n",
    "def test_api_health():\n",
    "    # Try a basic endpoint\n",
    "    response = requests.get(f\"{BASE_URL}/env/actions\", timeout=5)\n",
    "    assert response.status_code in [200, 404], \"API not responding\"\n",
    "\n",
    "def test_response_time():\n",
    "    start = time.time()\n",
    "    requests.get(f\"{BASE_URL}/env/actions\", timeout=5)\n",
    "    duration = time.time() - start\n",
    "    assert duration < 1.0, f\"Response time too slow: {duration}s\"\n",
    "\n",
    "# Run tests\n",
    "run_test(\"Server Reachable\", \"Health\", test_server_reachable)\n",
    "run_test(\"API Health\", \"Health\", test_api_health)\n",
    "run_test(\"Response Time < 1s\", \"Performance\", test_response_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf49ea5e",
   "metadata": {},
   "source": [
    "## 4. Authentication Flow Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîê AUTHENTICATION TESTS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "auth_token = None\n",
    "user_id = None\n",
    "\n",
    "def test_register():\n",
    "    global user_id\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/auth/register\",\n",
    "        json=TEST_USER\n",
    "    )\n",
    "    assert_status(response, 201)\n",
    "    data = response.json()\n",
    "    assert_json_keys(data, 'token', 'user')\n",
    "    user_id = data['user'].get('id')\n",
    "\n",
    "def test_login():\n",
    "    global auth_token\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/auth/login\",\n",
    "        json={\n",
    "            \"username\": TEST_USER[\"username\"],\n",
    "            \"password\": TEST_USER[\"password\"]\n",
    "        }\n",
    "    )\n",
    "    assert_status(response, 200)\n",
    "    data = response.json()\n",
    "    assert_json_keys(data, 'token', 'user')\n",
    "    auth_token = data['token']\n",
    "\n",
    "def test_invalid_login():\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/auth/login\",\n",
    "        json={\n",
    "            \"username\": \"invalid_user\",\n",
    "            \"password\": \"wrong_password\"\n",
    "        }\n",
    "    )\n",
    "    assert response.status_code in [401, 400], \"Should reject invalid credentials\"\n",
    "\n",
    "# Run tests\n",
    "run_test(\"User Registration\", \"Auth\", test_register)\n",
    "run_test(\"User Login\", \"Auth\", test_login)\n",
    "run_test(\"Invalid Login Rejection\", \"Auth\", test_invalid_login)\n",
    "\n",
    "if auth_token:\n",
    "    print(f\"\\nüîë Auth Token: {auth_token[:20]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b916b47b",
   "metadata": {},
   "source": [
    "## 5. Messages API Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76899b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üí¨ MESSAGES API TESTS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "message_id = None\n",
    "\n",
    "def test_send_message():\n",
    "    global message_id\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/api/messages\",\n",
    "        json={\n",
    "            \"channel\": \"general\",\n",
    "            \"content\": \"Test message\",\n",
    "            \"userId\": user_id or \"test-user\",\n",
    "            \"userName\": TEST_USER[\"name\"]\n",
    "        }\n",
    "    )\n",
    "    assert_status(response, 201)\n",
    "    data = response.json()\n",
    "    assert_json_keys(data, 'message')\n",
    "    message_id = data['message'].get('id')\n",
    "\n",
    "def test_get_messages():\n",
    "    response = requests.get(f\"{BASE_URL}/api/messages/general\")\n",
    "    assert_status(response, 200)\n",
    "    data = response.json()\n",
    "    assert isinstance(data, list), \"Should return array of messages\"\n",
    "\n",
    "def test_empty_message_rejection():\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/api/messages\",\n",
    "        json={\n",
    "            \"channel\": \"general\",\n",
    "            \"content\": \"\",  # Empty message\n",
    "            \"userId\": user_id or \"test-user\",\n",
    "            \"userName\": TEST_USER[\"name\"]\n",
    "        }\n",
    "    )\n",
    "    assert response.status_code in [400, 422], \"Should reject empty messages\"\n",
    "\n",
    "# Run tests\n",
    "run_test(\"Send Message\", \"Messages\", test_send_message)\n",
    "run_test(\"Get Messages\", \"Messages\", test_get_messages)\n",
    "run_test(\"Empty Message Rejection\", \"Messages\", test_empty_message_rejection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d141401",
   "metadata": {},
   "source": [
    "## 6. Calls API Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a0b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìû CALLS API TESTS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "call_id = None\n",
    "\n",
    "def test_create_call():\n",
    "    global call_id\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/calls/create\",\n",
    "        json={\n",
    "            \"type\": \"video\",\n",
    "            \"channelId\": f\"test-channel-{int(time.time())}\",\n",
    "            \"userId\": user_id or \"test-user\",\n",
    "            \"userName\": TEST_USER[\"name\"]\n",
    "        }\n",
    "    )\n",
    "    assert_status(response, 201)\n",
    "    data = response.json()\n",
    "    assert_json_keys(data, 'call')\n",
    "    call_id = data['call'].get('id')\n",
    "    assert call_id is not None, \"Call ID should be returned\"\n",
    "\n",
    "def test_get_call():\n",
    "    if not call_id:\n",
    "        raise AssertionError(\"No call_id available\")\n",
    "    response = requests.get(f\"{BASE_URL}/calls/{call_id}\")\n",
    "    assert_status(response, 200)\n",
    "    data = response.json()\n",
    "    assert_json_keys(data, 'call')\n",
    "\n",
    "def test_join_call():\n",
    "    if not call_id:\n",
    "        raise AssertionError(\"No call_id available\")\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/calls/{call_id}/join\",\n",
    "        json={\n",
    "            \"userId\": f\"user-{int(time.time())}\",\n",
    "            \"userName\": \"Test Participant\"\n",
    "        }\n",
    "    )\n",
    "    assert_status(response, 200)\n",
    "    data = response.json()\n",
    "    assert_json_keys(data, 'call')\n",
    "\n",
    "def test_leave_call():\n",
    "    if not call_id:\n",
    "        raise AssertionError(\"No call_id available\")\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/calls/{call_id}/leave\",\n",
    "        json={\n",
    "            \"userId\": user_id or \"test-user\"\n",
    "        }\n",
    "    )\n",
    "    assert_status(response, 200)\n",
    "\n",
    "# Run tests\n",
    "run_test(\"Create Call\", \"Calls\", test_create_call)\n",
    "run_test(\"Get Call Details\", \"Calls\", test_get_call)\n",
    "run_test(\"Join Call\", \"Calls\", test_join_call)\n",
    "run_test(\"Leave Call\", \"Calls\", test_leave_call)\n",
    "\n",
    "if call_id:\n",
    "    print(f\"\\nüìû Test Call ID: {call_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9737bab",
   "metadata": {},
   "source": [
    "## 7. RL Environment Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe0f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ü§ñ RL ENVIRONMENT TESTS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "def test_env_reset():\n",
    "    response = requests.post(f\"{BASE_URL}/env/reset\")\n",
    "    assert_status(response, 200)\n",
    "    data = response.json()\n",
    "    assert_json_keys(data, 'state', 'taskType')\n",
    "\n",
    "def test_env_get_state():\n",
    "    response = requests.get(f\"{BASE_URL}/env/state\")\n",
    "    assert_status(response, 200)\n",
    "    data = response.json()\n",
    "    assert_json_keys(data, 'state')\n",
    "\n",
    "def test_env_get_actions():\n",
    "    response = requests.get(f\"{BASE_URL}/env/actions\")\n",
    "    assert_status(response, 200)\n",
    "    data = response.json()\n",
    "    assert 'actions' in data or 'availableActions' in data, \"Should return actions\"\n",
    "\n",
    "def test_env_step():\n",
    "    # Reset first\n",
    "    requests.post(f\"{BASE_URL}/env/reset\")\n",
    "    \n",
    "    # Take a step\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/env/step\",\n",
    "        json={\n",
    "            \"action\": {\n",
    "                \"type\": \"send_message\",\n",
    "                \"channel\": \"general\",\n",
    "                \"content\": \"Test message\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    assert_status(response, 200)\n",
    "    data = response.json()\n",
    "    assert_json_keys(data, 'state', 'reward', 'done')\n",
    "\n",
    "def test_env_stats():\n",
    "    response = requests.get(f\"{BASE_URL}/env/stats\")\n",
    "    assert_status(response, 200)\n",
    "    data = response.json()\n",
    "    assert 'totalEpisodes' in data or 'stats' in data, \"Should return stats\"\n",
    "\n",
    "# Run tests\n",
    "run_test(\"RL Environment Reset\", \"RL\", test_env_reset)\n",
    "run_test(\"Get Environment State\", \"RL\", test_env_get_state)\n",
    "run_test(\"Get Available Actions\", \"RL\", test_env_get_actions)\n",
    "run_test(\"Execute Action Step\", \"RL\", test_env_step)\n",
    "run_test(\"Get Environment Stats\", \"RL\", test_env_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97f025e",
   "metadata": {},
   "source": [
    "## 8. Performance Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631aeded",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚ö° PERFORMANCE BENCHMARKS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "def benchmark_endpoint(name, method, url, data=None, iterations=10):\n",
    "    \"\"\"Benchmark an endpoint\"\"\"\n",
    "    times = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        start = time.time()\n",
    "        try:\n",
    "            if method == 'GET':\n",
    "                requests.get(url, timeout=5)\n",
    "            else:\n",
    "                requests.post(url, json=data, timeout=5)\n",
    "            duration = (time.time() - start) * 1000  # ms\n",
    "            times.append(duration)\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è Request {i+1} failed: {e}\")\n",
    "    \n",
    "    if times:\n",
    "        avg = sum(times) / len(times)\n",
    "        min_time = min(times)\n",
    "        max_time = max(times)\n",
    "        \n",
    "        print(f\"\\nüìä {name}:\")\n",
    "        print(f\"   Iterations: {len(times)}/{iterations}\")\n",
    "        print(f\"   Average: {avg:.2f}ms\")\n",
    "        print(f\"   Min: {min_time:.2f}ms\")\n",
    "        print(f\"   Max: {max_time:.2f}ms\")\n",
    "        \n",
    "        return times\n",
    "    return []\n",
    "\n",
    "# Benchmark different endpoints\n",
    "env_actions_times = benchmark_endpoint(\n",
    "    \"GET /env/actions\",\n",
    "    \"GET\",\n",
    "    f\"{BASE_URL}/env/actions\"\n",
    ")\n",
    "\n",
    "get_messages_times = benchmark_endpoint(\n",
    "    \"GET /api/messages/general\",\n",
    "    \"GET\",\n",
    "    f\"{BASE_URL}/api/messages/general\"\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "if env_actions_times and get_messages_times:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.boxplot([env_actions_times, get_messages_times], labels=['env/actions', 'messages'])\n",
    "    plt.ylabel('Response Time (ms)')\n",
    "    plt.title('Response Time Distribution')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(env_actions_times, marker='o', label='env/actions', alpha=0.7)\n",
    "    plt.plot(get_messages_times, marker='s', label='messages', alpha=0.7)\n",
    "    plt.xlabel('Request #')\n",
    "    plt.ylabel('Response Time (ms)')\n",
    "    plt.title('Response Time Trend')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab373dce",
   "metadata": {},
   "source": [
    "## 9. Integration Test - Complete User Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîÑ INTEGRATION TEST - COMPLETE USER FLOW\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "def test_complete_flow():\n",
    "    \"\"\"Test a complete user journey\"\"\"\n",
    "    flow_user = {\n",
    "        \"username\": f\"flow_test_{int(time.time())}\",\n",
    "        \"password\": \"testpass123\",\n",
    "        \"name\": \"Flow Test User\"\n",
    "    }\n",
    "    \n",
    "    # Step 1: Register\n",
    "    print(\"1Ô∏è‚É£ Registering user...\")\n",
    "    resp = requests.post(f\"{BASE_URL}/auth/register\", json=flow_user)\n",
    "    assert_status(resp, 201)\n",
    "    flow_user_id = resp.json()['user']['id']\n",
    "    print(f\"   ‚úÖ User registered: {flow_user_id}\")\n",
    "    \n",
    "    # Step 2: Login\n",
    "    print(\"2Ô∏è‚É£ Logging in...\")\n",
    "    resp = requests.post(f\"{BASE_URL}/auth/login\", json={\n",
    "        \"username\": flow_user[\"username\"],\n",
    "        \"password\": flow_user[\"password\"]\n",
    "    })\n",
    "    assert_status(resp, 200)\n",
    "    print(\"   ‚úÖ Login successful\")\n",
    "    \n",
    "    # Step 3: Send a message\n",
    "    print(\"3Ô∏è‚É£ Sending message...\")\n",
    "    resp = requests.post(f\"{BASE_URL}/api/messages\", json={\n",
    "        \"channel\": \"general\",\n",
    "        \"content\": \"Hello from integration test!\",\n",
    "        \"userId\": flow_user_id,\n",
    "        \"userName\": flow_user[\"name\"]\n",
    "    })\n",
    "    assert_status(resp, 201)\n",
    "    print(\"   ‚úÖ Message sent\")\n",
    "    \n",
    "    # Step 4: Create a call\n",
    "    print(\"4Ô∏è‚É£ Creating call...\")\n",
    "    resp = requests.post(f\"{BASE_URL}/calls/create\", json={\n",
    "        \"type\": \"video\",\n",
    "        \"channelId\": f\"flow-test-{int(time.time())}\",\n",
    "        \"userId\": flow_user_id,\n",
    "        \"userName\": flow_user[\"name\"]\n",
    "    })\n",
    "    assert_status(resp, 201)\n",
    "    flow_call_id = resp.json()['call']['id']\n",
    "    print(f\"   ‚úÖ Call created: {flow_call_id}\")\n",
    "    \n",
    "    # Step 5: Join the call\n",
    "    print(\"5Ô∏è‚É£ Joining call...\")\n",
    "    resp = requests.post(f\"{BASE_URL}/calls/{flow_call_id}/join\", json={\n",
    "        \"userId\": f\"participant-{int(time.time())}\",\n",
    "        \"userName\": \"Test Participant\"\n",
    "    })\n",
    "    assert_status(resp, 200)\n",
    "    print(\"   ‚úÖ Joined call\")\n",
    "    \n",
    "    # Step 6: Get call details\n",
    "    print(\"6Ô∏è‚É£ Getting call details...\")\n",
    "    resp = requests.get(f\"{BASE_URL}/calls/{flow_call_id}\")\n",
    "    assert_status(resp, 200)\n",
    "    call_data = resp.json()['call']\n",
    "    print(f\"   ‚úÖ Call has {len(call_data.get('participants', []))} participants\")\n",
    "    \n",
    "    # Step 7: Leave the call\n",
    "    print(\"7Ô∏è‚É£ Leaving call...\")\n",
    "    resp = requests.post(f\"{BASE_URL}/calls/{flow_call_id}/leave\", json={\n",
    "        \"userId\": flow_user_id\n",
    "    })\n",
    "    assert_status(resp, 200)\n",
    "    print(\"   ‚úÖ Left call\")\n",
    "    \n",
    "    print(\"\\nüéâ Complete flow test PASSED!\")\n",
    "\n",
    "# Run integration test\n",
    "run_test(\"Complete User Flow\", \"Integration\", test_complete_flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d0d563",
   "metadata": {},
   "source": [
    "## 10. Test Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä TEST RESULTS SUMMARY\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "if test_results:\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(test_results)\n",
    "    \n",
    "    # Overall stats\n",
    "    total = len(df)\n",
    "    passed = df['passed'].sum()\n",
    "    failed = total - passed\n",
    "    pass_rate = (passed / total * 100) if total > 0 else 0\n",
    "    avg_duration = df['duration'].mean()\n",
    "    \n",
    "    print(f\"Total Tests: {total}\")\n",
    "    print(f\"Passed: {passed} ‚úÖ\")\n",
    "    print(f\"Failed: {failed} ‚ùå\")\n",
    "    print(f\"Pass Rate: {pass_rate:.1f}%\")\n",
    "    print(f\"Average Duration: {avg_duration:.2f}ms\\n\")\n",
    "    \n",
    "    # Results by category\n",
    "    print(\"\\nüìã Results by Category:\")\n",
    "    category_stats = df.groupby('category').agg({\n",
    "        'passed': ['sum', 'count'],\n",
    "        'duration': 'mean'\n",
    "    }).round(2)\n",
    "    category_stats.columns = ['Passed', 'Total', 'Avg Duration (ms)']\n",
    "    category_stats['Pass Rate (%)'] = (category_stats['Passed'] / category_stats['Total'] * 100).round(1)\n",
    "    display(category_stats)\n",
    "    \n",
    "    # Failed tests\n",
    "    failed_tests = df[df['passed'] == False]\n",
    "    if len(failed_tests) > 0:\n",
    "        print(\"\\n‚ùå Failed Tests:\")\n",
    "        for _, test in failed_tests.iterrows():\n",
    "            print(f\"   - {test['name']} ({test['category']})\")\n",
    "            print(f\"     Error: {test['error']}\")\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Pie chart - Pass/Fail\n",
    "    axes[0].pie([passed, failed], labels=['Passed', 'Failed'], autopct='%1.1f%%',\n",
    "                colors=['#4CAF50', '#F44336'], startangle=90)\n",
    "    axes[0].set_title('Overall Test Results')\n",
    "    \n",
    "    # Bar chart - By category\n",
    "    category_pass_rate = df.groupby('category')['passed'].apply(lambda x: (x.sum() / len(x) * 100))\n",
    "    category_pass_rate.plot(kind='bar', ax=axes[1], color='skyblue')\n",
    "    axes[1].set_title('Pass Rate by Category')\n",
    "    axes[1].set_ylabel('Pass Rate (%)')\n",
    "    axes[1].set_ylim([0, 100])\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Duration chart\n",
    "    df_passed = df[df['passed'] == True]\n",
    "    if len(df_passed) > 0:\n",
    "        df_passed.plot(kind='scatter', x='name', y='duration', ax=axes[2], s=100, color='green', alpha=0.6)\n",
    "        axes[2].set_title('Test Duration (Passed Tests)')\n",
    "        axes[2].set_ylabel('Duration (ms)')\n",
    "        axes[2].set_xlabel('')\n",
    "        axes[2].tick_params(axis='x', rotation=90)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Export results\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"test_results_{timestamp}.json\"\n",
    "    \n",
    "    report = {\n",
    "        'timestamp': timestamp,\n",
    "        'summary': {\n",
    "            'total': total,\n",
    "            'passed': passed,\n",
    "            'failed': failed,\n",
    "            'pass_rate': pass_rate,\n",
    "            'avg_duration_ms': avg_duration\n",
    "        },\n",
    "        'tests': test_results\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nüíæ Results exported to: {filename}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No test results available\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ TESTING COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
